{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport os\nimport cv2\nimport keras\nfrom keras.models import Sequential,Model\nfrom keras.layers import Dense,MaxPooling2D,Add,ReLU,Activation,Conv2D,Flatten,Reshape,PReLU,Concatenate,Conv2DTranspose,Dropout,BatchNormalization,Lambda,Input\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.layers.advanced_activations import LeakyReLU \nfrom keras.layers import Concatenate\nfrom keras import optimizers\nfrom sklearn.preprocessing import StandardScaler\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def down_sample_2D(inputs,channels,out_size=(6,14)):\n    x=Conv2D(channels,kernel_size=1,strides=(1,1))(inputs)\n    x=tf.image.resize(x,out_size,method='bilinear',preserve_aspect_ratio=False,antialias=True,name=None)\n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def face_detector():\n    ip=Input(shape=(64,128,3))\n    x=Lambda(lambda x : (x/255))(ip)\n    \n    x=Conv2D(64,kernel_size = 3,strides = (1,1), padding='same')(x)\n    x=Conv2D(64,kernel_size = 3,strides = (1,1), padding='valid')(x)\n    \n    x=Conv2D(64,kernel_size = 3,strides = (2,2), padding='same')(x)\n    x=ReLU()(x)\n    x=BatchNormalization()(x)\n    \n    x=Conv2D(128,kernel_size = 3,strides = (1,1), padding='same')(x)\n    x=Conv2D(128,kernel_size = 3,strides = (1,1), padding='same')(x)\n    \n    x=Conv2D(128,kernel_size = 3,strides = (2,2), padding='valid')(x)\n    x=ReLU()(x)\n    x=BatchNormalization()(x)\n    \n    x=Conv2D(256,kernel_size = 3,strides = (1,1), padding='same')(x)\n    x=Conv2D(256,kernel_size = 3,strides = (1,1), padding='same')(x)\n    x=Conv2D(256,kernel_size = 3,strides = (1,1), padding='same')(x)\n    x=Conv2D(256,kernel_size = 3,strides = (1,1), padding='same')(x)\n    \n    x=Conv2D(256,kernel_size = 3,strides = (2,2), padding='valid')(x)\n    x=ReLU()(x)\n    x=BatchNormalization()(x)\n    \n    x=Conv2D(512,kernel_size = 3,strides = (1,1), padding='same')(x)\n    x=Conv2D(512,kernel_size = 3,strides = (1,1), padding='same')(x)\n    x=Conv2D(512,kernel_size = 3,strides = (1,1), padding='same')(x)\n    x=Conv2D(512,kernel_size = 3,strides = (1,1), padding='same')(x)\n    \n    x=Conv2D(256,kernel_size = 3,strides = (2,2), padding='valid')(x)\n    x=ReLU()(x)\n    x=BatchNormalization()(x)\n    \n    x=Conv2D(128,kernel_size = 3,strides = (1,1), padding='same')(x)\n    x=Conv2D(128,kernel_size = 3,strides = (1,1), padding='same')(x)\n    x=Conv2D(128,kernel_size = 3,strides = (1,1), padding='same')(x)\n    \n    x=Flatten()(x)\n    x=Dense(388)(x)\n    \n    model=Model(inputs=ip,outputs=x)\n    return model\nfd=face_detector()\nfd.summary()\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def face_detector1():\n    ip=Input(shape=(64,128,3))\n    x=Lambda(lambda x : (x/255))(ip)\n    x1=Conv2D(64,kernel_size = 3,strides = (1,1), padding='same')(x)\n    x=ReLU()(x1)\n    x=Conv2D(64,kernel_size = 3,strides = (1,1), padding='same')(x)\n    x=ReLU()(x)\n    x=Conv2D(64,kernel_size = 3,strides = (1,1), padding='same')(x)\n    x=ReLU()(x)\n    x=BatchNormalization()(x)\n    x=Add()([x1,x])\n    x2=Conv2D(128,kernel_size = 3,strides = (1,1), padding='same')(x)\n    x=ReLU()(x)\n    x=Conv2D(128,kernel_size = 3,strides = (1,1), padding='same')(x)\n    x=ReLU()(x)\n    x=Conv2D(128,kernel_size = 3,strides = (1,1), padding='same')(x)\n    x=ReLU()(x)\n    x=BatchNormalization()(x)\n    x=Add()([x2,x])\n    x=Conv2D(256,kernel_size = 3,strides = (2,2), padding='valid')(x)\n    x=Conv2D(256,kernel_size = 3,strides = (2,2), padding='valid')(x)\n    x=Conv2D(256,kernel_size = 3,strides = (2,2), padding='valid')(x)\n    x=Conv2D(256,kernel_size = 3,strides = (2,2), padding='valid')(x)\n    x=ReLU()(x)\n    x=BatchNormalization()(x)\n    x=Conv2D(256,kernel_size = 3,strides = (1,1), padding='same')(x)\n    x=Conv2D(256,kernel_size = 3,strides = (1,1), padding='same')(x)\n    x=Flatten()(x)\n    x=Dense(388)(x)\n    \n    model=Model(inputs=ip,outputs=x)\n    return model\n    \nfd=face_detector1()\nfd.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_full=[]\nx_fd_train=[]\ny_fd_train=[]\ndata=np.load('../input/helen-data/helen_data.npy',allow_pickle=True)\nfor i in range(len(data)):\n    img=data[i][0][:64,:,:]\n    x_full.append(data[i][0])\n    x_fd_train.append(img)\n    y_fd_train.append(data[i][1]+data[i][2])\n    \nsc=StandardScaler()\ny_fd_train1=sc.fit_transform(y_fd_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_fd_train=np.array(x_fd_train)\ny_fd_train1=np.array(y_fd_train1)\nopt=keras.optimizers.Adam(lr=0.0009)\nfd.compile(optimizer=opt, loss='mean_squared_error',metrics=['accuracy'])\nhistory=fd.fit(x_fd_train,y_fd_train1,batch_size=16,epochs=30,verbose=1,validation_split=0.01)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ind=2210\ntst_im=x_full[ind]\ntst_pts=y_fd_train[ind]\nim=np.resize(x_fd_train[ind],(1,64,128,3))\nlower=np.zeros((128,128,3),dtype=np.int8)\npred_pts=fd.predict(im)\npts=sc.inverse_transform(pred_pts)\npts=pts[0]\nx_t=list(map(int,tst_pts[:194]))\ny_t=list(map(int,tst_pts[194:]))\nx=list(map(int,pts[:194]))\ny=list(map(int,pts[194:]))\n#img=x_train[250]\nfor i in range(194):\n    #cv2.circle(tst_im,(x_t[i],y_t[i]),1,(255,0,0),1)\n    cv2.circle(lower,(x[i],y[i]),1,(255,0,0),1)\n    \nimg=np.concatenate((tst_im[:64],lower[64:]),axis=0)\nplt.subplot(1,2,1)\nplt.imshow(img)\nplt.subplot(1,2,2)\nplt.imshow(tst_im)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv2.imwrite('tr4.jpg',img)\ncv2.imwrite('ts4.jpg',tst_im)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import plot_model\nplot_model(fd, to_file='fd_model.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def encoder():\n    ip=Input(shape=(64,128,3))\n    #org=Input(shape=(128,128,3))\n    x1=Lambda(lambda x : (x/255))(ip)\n    #Encoder\n    x=Conv2D(8,kernel_size = 3,strides = (1,1))(x1)\n    x=BatchNormalization()(x)\n    x=PReLU()(x)\n    \n    x=Conv2D(8,kernel_size = 3,strides = (1,1))(x)\n    x=BatchNormalization()(x)\n    x=PReLU()(x)\n    #model.add(BatchNormalization())\n    x=Conv2D(16,kernel_size = 3,strides = (1,1))(x)\n    x=BatchNormalization()(x)\n    x=PReLU()(x)\n    \n    #d=Lambda(lambda i : down_sample_2D(i,32,out_size=(6,14)))(x)\n    d=Conv2D(64,kernel_size=(11,11), strides=(8,8))(x)\n    #model.add(BatchNormalization())\n    x=Conv2D(16,kernel_size = 3,strides = (2,2))(x)\n    x=BatchNormalization()(x)\n    x=PReLU()(x)\n    #model.add(BatchNormalization())        \n    x=Conv2D(32,kernel_size = 3,strides = (2,2))(x)\n    x=BatchNormalization()(x)\n    x=PReLU()(x)\n    #model.add(BatchNormalization())\n    x=Conv2D(64,kernel_size = 3,strides = (2,2))(x)\n    x=BatchNormalization()(x)\n    x=PReLU()(x)\n    #fully connected\n    x=Add()([x,d])\n    x=Flatten()(x)\n    x=Dense(3708)(x)\n    \n    model=Model(inputs=ip,outputs=x)\n    return model\n\n    #Decoder\ndef decoder():\n    ip=Input(shape=(None,3708+388))\n    x=Reshape(target_shape=(4,8,128),input_shape = (3708+388,))(ip)\n    x=Conv2DTranspose(64,kernel_size = 9,strides =(1,1),padding = \"SAME\")(x)\n    x=BatchNormalization()(x)\n    x=LeakyReLU(0.2)(x)\n    #model.add(BatchNormalization())\n    x=Conv2DTranspose(32,kernel_size = 6,strides =(2,2),padding = \"SAME\")(x)\n    x=BatchNormalization()(x)\n    x=LeakyReLU(0.2)(x)\n    #model.add(BatchNormalization())\n    x=Conv2DTranspose(16,kernel_size = 3,strides =(2,2),padding = \"SAME\")(x)\n    x=BatchNormalization()(x)\n    x=LeakyReLU(0.2)(x)\n    #model.add(BatchNormalization())\n    x=Conv2DTranspose(8,kernel_size = 3,strides =(2,2),padding = \"SAME\")(x)\n    x=BatchNormalization()(x)\n    x=LeakyReLU(0.2)(x)\n    #model.add(BatchNormalization())\n    x=Conv2DTranspose(3,kernel_size = 2,strides =(2,2),padding = \"SAME\")(x)\n    x=BatchNormalization()(x)\n    x=LeakyReLU(0.2)(x)\n    \n    #out=Concatenate(axis=1)([ip,x])\n    \n    model=Model(inputs=ip,outputs=x)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"e=encoder()\ne.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def sr():\n  ip=Input(shape=(64,128,3))\n  #x=Lambda(lambda x:x/255)(ip)\n\n  x=Conv2D(64,kernel_size=9,strides=(1,1),padding='same')(ip)\n  x1=PReLU()(x)\n\n  x=Conv2D(64,kernel_size=3,strides=(1,1),padding='same')(x1)\n  x=BatchNormalization()(x)\n  x=PReLU()(x)\n  x=Conv2D(64,kernel_size=3,strides=(1,1),padding='same')(x)\n  x=BatchNormalization()(x)\n  x2=Add()([x1,x])\n\n  x=Conv2D(64,kernel_size=3,strides=(1,1),padding='same')(x2)\n  x=BatchNormalization()(x)\n  x=PReLU()(x)\n  x=Conv2D(64,kernel_size=3,strides=(1,1),padding='same')(x)\n  x=BatchNormalization()(x)\n  x3=Add()([x2,x])\n\n  x=Conv2D(64,kernel_size=3,strides=(1,1),padding='same')(x3)\n  x=BatchNormalization()(x)\n  x=PReLU()(x)\n  x=Conv2D(64,kernel_size=3,strides=(1,1),padding='same')(x)\n  x=BatchNormalization()(x)\n  x4=Add()([x3,x])\n\n  x=Conv2D(64,kernel_size=3,strides=(1,1),padding='same')(x4)\n  x=BatchNormalization()(x)\n  x=PReLU()(x)\n  x=Conv2D(64,kernel_size=3,strides=(1,1),padding='same')(x)\n  x=BatchNormalization()(x)\n  x5=Add()([x4,x])\n\n  x=Conv2D(64,kernel_size=3,strides=(1,1),padding='same')(x5)\n  x=BatchNormalization()(x)\n  x=PReLU()(x)\n  x=Conv2D(64,kernel_size=3,strides=(1,1),padding='same')(x)\n  x=BatchNormalization()(x)\n  x6=Add()([x5,x])\n\n  x=Conv2D(64,kernel_size=3,strides=1,padding='same')(x6)\n  x=BatchNormalization()(x)\n  x7=Add()([x1,x])\n\n  x=Conv2D(256,kernel_size=3,strides=1,padding='same')(x7)\n  #x=UpSampling2D(size=2)(x)\n  x=PReLU()(x)\n\n  x=Conv2D(256,kernel_size=3,strides=1,padding='same')(x)\n  #x=UpSampling2D(size=2)(x)\n  x=PReLU()(x)\n\n  x=Conv2D(3,kernel_size=9,strides=1,padding='same')(x)\n\n  model=Model(inputs=ip,outputs=x)\n  return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#s=sr()\nopt=keras.optimizers.Adam(lr=0.0006)\ns.compile(optimizer=opt, loss=norm_loss,metrics=['accuracy'])\nhistory=s.fit(x_sr,y_sr,batch_size=16,epochs=10,verbose=1,validation_split=0.002)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for layer in s.layers[:39]:\n    layer.trainable=False\ns.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for layer in fd.layers:\n    layer.trainable=False\nfd.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ip=Input(shape=(64,128,3))\nf=fd(ip)\ne=encoder()(ip)\ndense_rep=keras.layers.concatenate([f,e],axis=1)\nd=decoder()(dense_rep)\nsr=s(d)\nae=Model(inputs=ip,outputs=sr)\n#ae=Sequential()\n#ae.add(f)\n#ae.add(e)\n#ae.add(d)\n#ae.add(s)\nae.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\ndef norm_loss(a,b):\n    loss=tf.math.reduce_mean((((a/255))-b)**2)\n    return loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"opt=keras.optimizers.Adam(lr=0.0008)\nae.compile(optimizer=opt, loss=norm_loss,metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history=ae.fit(x_train,y_train,batch_size=16,epochs=10,verbose=1,validation_split=0.01)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ae.save('AESRFD_0.0044_7K.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"srgan=keras.models.load_model('../input/superresolution/SrGanRGB_3e-4.h5',custom_objects={'norm_loss':norm_loss})\nsrgan.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=Model(inputs=srgan.inputs,outputs=srgan.layers[21].output)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"out=ae.predict(np.resize(x_train[178],(1,64,128,3)))\nout=np.resize(out,(64,128,3))/10\n#out=np.multiply(out,255)\nup=x_train[178]\nplt.subplot(2,2,1)\nplt.imshow(up)\nplt.subplot(2,2,2)\nplt.imshow(up)\nplt.subplot(2,2,3)\nplt.imshow(out)\nplt.subplot(2,2,4)\nplt.imshow(y_train[178])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.average(out)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n'''square = 2\nix = 1\nfor _ in range(square):\n\tfor _ in range(square):\n\t\t# specify subplot and turn of axis\n\t\tax = plt.subplot(square, square, ix)\n\t\tax.set_xticks([])\n\t\tax.set_yticks([])\n\t\t# plot filter channel in grayscale\n\t\tplt.imshow(f[0, :, :, ix-1], cmap='gray')\n\t\tix += 1\n# show the figure\nplt.show()'''\nplt.imshow(f[0,:,:,23],cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for layer in s.layers[:39]:\n    layer.trainable=False\n#len(srgan.layers)\ns.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f_model=Sequential()\nf_model.add(g)\nf_model.add(srgan)\nf_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train=[]\ny_train=[]\nn=0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cascade=cv2.CascadeClassifier('../input/haarcascadefrontalfaces/haarcascade_frontalface_default.xml')\nfor loc in os.listdir('../input/celeba-dataset/img_align_celeba/img_align_celeba/'):\n    im=cv2.imread('../input/celeba-dataset/img_align_celeba/img_align_celeba/'+loc)\n    gray=cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n    faces=cascade.detectMultiScale(gray,1.3,5)\n    for (x,y,w,h) in faces:\n        face=im[y:y+h,x:x+w]\n    if n<7000:\n        face=cv2.resize(face,(128,128))\n        face=cv2.cvtColor(face,cv2.COLOR_BGR2RGB)\n        #c=face[:64,:]\n        #b=cv2.blur(face[64:,:],(10,10))\n        #b=np.full((64,128,3),255)\n        #x=np.concatenate((c,b),axis=0)\n        #y=cv2.resize(face,(128,128))\n        x_train.append(face[:64,:])\n        y_train.append(face[64:,:])\n        if n%1000==0:\n            print(n,end=' ')\n        n+=1\n    else:\n        break    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"k=0\nx_sr=[]\ny_sr=[]\ncascade=cv2.CascadeClassifier('../input/haarcascadefrontalfaces/haarcascade_frontalface_default.xml')\nfor loc in os.listdir('../input/celeba-dataset/img_align_celeba/img_align_celeba/'):\n    im=cv2.imread('../input/celeba-dataset/img_align_celeba/img_align_celeba/'+loc)\n    gray=cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n    faces=cascade.detectMultiScale(gray,1.3,5)\n    for (x,y,w,h) in faces:\n        face=im[y:y+h,x:x+w]\n    if k<5000:\n        face=cv2.resize(face,(128,128))\n        face=cv2.cvtColor(face,cv2.COLOR_BGR2RGB)\n        #c=face[:64,:]\n        #b=cv2.blur(face[64:,:],(10,10))\n        #b=np.full((64,128,3),255)\n        #x=np.concatenate((c,b),axis=0)\n        #y=cv2.resize(face,(128,128))\n        x_sr.append(cv2.blur(face[64:,:],(10,10)))\n        y_sr.append(face[64:,:])\n        if k%500==0:\n            print(k,end=' ')\n        k+=1\n    else:\n        break    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_sr=np.array(x_sr)\nx_sr=x_sr/255.0\ny_sr=np.array(y_sr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"opt=keras.optimizers.Adam(lr=0.001)\nf_model.compile(optimizer=opt, loss=norm_loss,metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train=np.array(x_train)\ny_train=np.array(y_train)\ny_train.shape\n#plt.imshow(np.resize(x_train[0],(128,128,3)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history=f_model.fit(x_train,y_train,batch_size=16,epochs=10,verbose=1,validation_split=0.01)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import cv2\n#import matplotlib.pyplot as plt\n#%matplotlib inline\n#img=cv2.imread('../input/images1/Capture1.PNG')\nip=x_train[23]\n#ip=cv2.resize(img,(128,128))\nip=cv2.cvtColor(ip,cv2.COLOR_BGR2RGB)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\n#op=f_model.predict(ip)\nplt.imshow(np.resize(x_train[1],(128,128,3)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a=(3,128,128,3)\nb=a[0]//2\nprint(b)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}